---
title: "Power-ful rankings of NCAA men's basketball teams"
format: 
  pdf:
    mainfont: Liberation Serif
    monofont: Liberation Mono
    fontsize: 12px
    colorlinks: false
    cite-method: biblatex
    links-as-notes: true
author: "Hugo Hinckfuss, Josh Livingston, Magnus Miller (Section #002)"
date: 2024-04-29
bibliography: references.bib
biblio-title: References
biblio-style: authoryear
execute:
  echo: false
  warning: false
editor: visual
---

```{r load-packages}
library(appm3310.final)

library(dplyr)
library(purrr)
library(tibble)
library(ggplot2)

library(gt)
```

```{r setup-gt}
library(knitr)
knit_print.gt <- function(x, ...) {
  stringr::str_c(
    "<div style='all:initial';>\n", 
    gt::as_raw_html(x), 
    "\n</div>"
  ) |> 
    knitr::asis_output()
    
}
registerS3method(
  "knit_print", 'gt_tbl', knit_print.gt, 
  envir = asNamespace("gt")
)
```

## Abstract

The following paper discussed the derivation and development of multiple ranking schemes used to rank Men’s NCAA College basketball teams in uneven paired competition (UEPC). This paper’s motive to explore ranking schemes stems from the work of James P Keener who first used similar strategies in an application to rank college football teams. Through the direct use of the Perron-Frobenius theorem and numerical experiments to derive eigenvalues and eigenvectors, this paper developed a ranking scheme for uneven paired competition directly using the Perron-Frobenius theorem using a base matrix comprised of wins and losses. This paper then expanded by considering other base matrices to compare which include proportion of points scored and the square-root of points scored among others, eventually comparing them to the existing ranking methods such as the AP Coaches Poll. Results showed that limitations in the original UEPC system in terms of sparsity heavily hinder the ranking schemes that can be developed in this manner. Understanding this, however, by taking Keener’s original work for ranking college football teams and applying the same methodology to college basketball, this paper has shown that with small alterations to the Perron-Frobenius theorem and through experimentation, similar ranking schemes can be developed for any other uneven paired competition based sport or event.

## Attribution

Josh Livingston worked on the mathematical formulation used in the paper, developed and wrote the R code used to test the various ranking schemes, and handled the compilation of our work in Markdown. Hugo Hinckfuss wrote the introduction and worked on the mathematical formulation used throughout the paper, most notably in the development of the Direct Method ranking scheme. And Magnus Miller worked on the mathematical formulation pertaining to the Perron-Frobenius theorem, the abstract, and discussion as well as in editing the final paper.

## Introduction

Every spring, the discourse surrounding collegiate basketball reaches its zenith as enthusiasts engage in discussions regarding the eventual supremacy of a particular team by the end of March. This discourse, however, is often clouded by subjective polls and rankings, notably those conducted by entities such as the Associated Press (AP), leading to confusion, disagreement, and frustration among fans who advocated for their respective teams. While certain publications propose alternative indices based on mathematical models, these methodologies often remain opaque to the general public due to the perceived complexity associated with mathematical concepts.

Our group's interest in the ranking of collegiate basketball teams peaked during this year's March Madness tournament, where several high-seeded teams succumbed to the unexpected triumphs of lower-seeded opponents. These upsets pushed our group to envision a future where a mathematically-driven ranking system could not only corroborate traditional voter-based polls but also enhance the precision of predicting teams' success in tournaments.

The difficulty in developing a ranking scheme in this type of system stems from the concept of uneven paired competition (UEPC), or comparison. In a UEPC based system, the outcomes of any paired comparison, or competition in the case of sports, is known but the full set of outcomes is incomplete. In the case of college basketball, this UEPC system has known outcomes (wins or losses) for a given game (comparison) throughout the  season, but is incomplete as not every college team plays each other. In his paper, The Perron-Frobenius Theorem and the Ranking of Football Teams, James P Keener [@keener_1993_the] discovered that many ranking methodologies heavily leveraged the Perron-Frobenius theorem, which provided an elegant solution to the challenge of uneven paired competition. 

This paper aimed to expand Keener’s work to the world of NCAA Men’s Basketball as it delved into various ranking methods, highlighting the utilization of the Perron-Frobenius theorem, eigenvalue computation techniques, fixed-point theorems, and probabilistic modeling. Each of the methods discussed in this paper formulate a ranking problem as a linear eigenvalue problem, directly applying the Perron-Frobenius theorem. Through various solutions to the entries of our matrix were we able to develop varying ranking schemes that prioritize different elements of college basketball to reveal the best.

This paper first develops an understanding of the Perron-Frobenius theorem through a pseudo-derivation of the theorem and expands on the mathematical formulation used throughout the development of the ranking schemes later introduced. The paper then builds on the Perron-Frobenius theorem to develop a direct ranking approach using wins and losses. Later the paper expands on this method deriving ranking priorities based on other factors of the game such as proportion of points scored and square root of points scored among others. Following the development of the ranking schemes, the paper analyzes the effectiveness of the proposed ranking schemes in comparison to the AP Top 25 poll and proposed hypotheses as to the successes and failures of the modeled schemes accuracy and validity. 

Ultimately, we concluded by presenting the results derived from the application of these diverse ranking systems, aiming to showcase a collegiate basketball ranking that more accurately reflected the true capabilities of teams participating in March Madness. In the end, however, we discuss how the sparsity of the data used in constructing our base matrices percolates throughout the formulation of our ranking schemes making it difficult to assess their viability. We propose, however, that due to the limitation of the original dataset, these ranking schemes may be better applied to NBA basketball where the UEPC is less uneven.

## Mathematical Formulation

### The Direct Method

This first method is regarded as the most direct method in ranking entities. In this method, we will simply assign a score to a team, depending on their result against an opposing team. The score $a_{ij}$ given to the team will depend on the strength of the opponent, the margin of the scoring and the outcome of the game (win, loss or draw). 

We will introduce the vector $\vec r$, which will represent the ranking values of teams, with positive component $r_{j}$ representing the strength of the $j^{th}$ team (the opposition team). Then, the score for team $i$ will be defined as 

$$
s_{i}=\frac {1}{n_{i}}\sum_{j=1}^{N}a_{ij}r_{j}
$$

with $a_{ij}$ being a nonnegative number depending on the aforementioned factors between teams $i$ and $j$. $N$ will be the total number of teams in the system, which in our case will be larger than simply the teams that were allowed to play in March Madness, as we will require more data points to increase the rigidity of the standings. We will also have a focus on the PAC12 Conference, as it will be easier to see the effectiveness of this method relative to both their conference records, but also their AP Rankings and their ultimate performances in the March Madness tournament. 

The matrix $A$ with entries $a_{ij}$ is referred to as a preference matrix. In our case, we will notate the entry of $a_{ij}$ as 1 if team $i$ is victorious, or 0 if the game is lost. There is also a column for draws, with an entry value of ½, but these will always be empty as there are no draws in collegiate basketball, yet this column will be value for use in other applications. The reason why the sum will be divided by $n_{ij}$, the number of matches between teams $i$ and $j$, is to ensure teams cannot accumulate and artificially large score through playing more games than their competitors. 

Next, the strength (which will be ordered to provide rank) of a participant will be a function of the teams score, given by 

$$
A\vec r=\lambda\vec r
$$

where $A$ is the matrix containing entries ${a_{ij}}$. Thus, the ranking vector r is a positive eigenvector from the positive matrix A.

The Perron-Frobenius Theorem tells us that when the non-trivial matrix A has nonnegative entries, there exists an eigenvector $\vec r$ with nonnegative entries, which have a corresponding eigenvector $\lambda$. Furthermore, if $A$ is irreducible, eigenvector $\vec r$ will have only unique and positive entries.

In order to calculate the eigenvector, we can take advantage of the power method - namely, the fact that the ranking vector $\vec r$ will correspond to the largest eigenvalue of $A$, ie:

$$
\lim_{n\to inf}\frac {A^n\vec r_{0}}{\left| A^n\vec r_{0} \right|}=\vec r
$$

for an nonnegative vector $\vec r_{0}$.

Initially, with the system devised, all teams would be given an initial ranking of one. Then the $i^{th}$ component of the vector $A^2r_{0}$ would represent the average winning percentage of the teams defeated by team i. Thus, this component of the vector would provide the reader with information regarding the strength of a teams schedule, and it is arguably a stronger metric than simply winning percentage. The predominant issue with this figure is that it places such a significant portion of the score of the strength of the schedule. 

This system works really well for systems where teams play each other often during a season, and have different schedules i.e the NBA and MLB regular seasons (no team plays every team the same amount of times). In this case, $a_{ij}$ will be the total victories of team $i$ over $j$. Intuitively, with more and more games, this system will become a superior indicator of the relative strength of the two teams.

The issue arises in seasons of collegiate basketball and football, where teams will play each other very few times, often once. In this situation, an arbitrary score of 1,½ or 0 only provides information for the outcome. Thus, there will be lost information on how close the teams were in ability, as the same score is provided for a 120-60 win and an 120-1119 win. Furthermore, a team that is winless in a season will have rank zero and will therefore not contribute to their opponents score at all, which actually makes playing these teams harmful, or worse than not playing them at all, as it will only divide the numerator by a larger number.

In order to account for this, we can instead distribute a single point between the two teams in a continuous manner. This can be achieved through distributing the point according to the points scored by each team. Suppose team $i$ scored $s_{ij}$ points and team $j$ scored $s_{ji}$ points when they played each other, the input $a_{ij}$ may be represented as

$$
a_{ij}=\frac {s_{ij}}{s_{ij}+s_{j}}
$$

for team $i$.

For application in other sports, particularly potentially low scoring sports such as football or soccer, the earlier problem arises if the losing team fails to score a single point/goal. In soccer, a score of 1-0 is regarded as a tight result, yet the losing team would still be awarded 0. To account for this, we will assign

$$
a_{ij}=\frac {s_{ij}+1}{s_{ij} + s_{ji} + 2}
$$

To further enforce the rigidity of this process, we also have to account for the fact that when a team is winning comfortably, they will often rotate weaker players or simply try less. In our system, the winning team showing ‘mercy’ simply weakens their potential score. To fix this problem, we also tried distributing the points in a non-linear manner. A function that we tried to use to more effectively rank teams was:

$$
a_{ij}=h\left(\frac {s_{ij}+1}{s_{ij}+s_{ji}+2}\right)
$$

$$
h(x)=\frac {1}{2}+\frac {1}{2}s\left(x-\frac {1}{2}\right)\sqrt {\left|2x-1\right|}
$$

where $s(x)$ is the sign of $x$.

## **Numerical Results**

### **Data**

We obtained team-game level data from [sports-reference.com](https://stathead.com/basketball/cbb/team-game-finder.cgi?request=1&comp_type=reg&game_status=1&order_by=date&match=team_game&year_max=2024&order_by_asc=1&timeframe=seasons&comp_id=NCAAM&year_min=2024) for the 2023-24 NCAA men's regular season. After doing basic data preparation, we bundled the data in an R package in this report. The R package, including the data and code for the computation, figures, and tables, is available on [Github](https://github.com/joshwlivingston/appm3310.final).

A sample of the data is available below. In total we have a 10,654 x 7 dataset. There are two rows per game in, one row per team. And for each team-game with have 7 columns: the team, date, home/away designation, opponent, result, team's score, and opponent's score.

```{r preview-data}
#| fig-align: center

ncaam |> 
  head(10) |> 
  select(team, opp, result, team_score, opp_score) |> 
  gt() |> 
  tab_caption("Sample of prepared NCAA men's basketball data")
```

<br>

### Eigenvector computation

#### Win-loss matrix

We explore various methodologies to compute $a_{ij}$. First, we take the result of each game, and assign to the team a 0 for a loss, a 0.5 for a tie, and a 1 for a win. Then, we add the results and aggregate into a square matrix, denoted $A_{1}$ with entries $a_{1ij}: i,j=1,2,...,362$. A sample of this matrix is shown below. For simplicity, we'll let $B_{1}$ refer to the $4x4$ sample of $A_{1}$ with corresponding entries $b_{1ij}: i,j=1,2,3,4$.

```{r a1-preview}
ncaam_a1_tbl <- 
  ncaam |> 
  ranking_table_prep_direct_win_loss()

final_four <- c("Duke", "NC State", "Purdue", "Tennessee")
ncaam_a1_tbl |> 
  view_subset(final_four) |> 
  gt(rowname_col = "team") |> 
  tab_caption(md("Sample of win-loss matrix"))
```

<br>

In matrix notation, the matrix $B$ is $$ 
B=\begin{pmatrix} 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 0 \end{pmatrix}
$$

The matrix entries $b_{1ij}\in B_{1}$ line up with team-game level results from the regular season.

```{r final-four-game-results}
game_result_caption <- 
  "Regular season results for teams in the NCAA men's 2024 final four"

ncaam |> 
  filter(team %in% final_four & opp %in% final_four) |> 
  mutate(
    team_opp = map2(team, opp, c),
    team_opp = map(team_opp, sort),
    team_opp = map_chr(team_opp, paste, collapse = "")
  ) |> 
  mutate(i = row_number(), .by = "team_opp") |> 
  filter(i == 1) |> 
  select(-team_opp, -i) |> 
  gt() |> 
  tab_caption(game_result_caption)
```

A potential downside to this method, is that teams that have never matched have the same entry for $b_{ij}$ as teams that have lost to another team. For both of this scenarios, $b_{ij}=0$. You can see that $b_{21}=b_{23}=0$, where $b_{21}=0$ represents NC State's loss to Duke, and $b_{23}=0$ represents NC State and Purdue never having played a game against each other in the regular season So, in this scenario, we lose information about losses. This can lead to teams with losses to have an inflated ranking.

#### Eigenvalue approximation

We denote the eigenvalue $\lambda$ for matrix $A_{1}$ as $\lambda_{1}$.

To approximate $\lambda_{1}$, we employ the power method. At each step of the power method, we compute the approximate eigenvalue $\lambda_{1i}$ where $i$ is the iteration step of the power method approximation, and $$\lim_{i  \to \inf} \lambda_{1i}=\lambda_{1}$$

After approximation, we observe $\lambda_{1i}$ converging to $\lambda_{1}$, shown in the figure below.

```{r a1-lambda-plot}
ncaam_a1_eigenvalues <- 
  ncaam_a1_tbl |> 
  to_matrix() |> 
  eigenvalues_power_method()

eigenvalue_table_a1 <- ncaam_a1_eigenvalues$eigenvalue_table
iterations_a1 <- nrow(eigenvalue_table_a1)
eigenvalue_a1 <- eigenvalue_table_a1$lambda[iterations_a1]

plot_caption <- sprintf(
  "Values of lambda converge to approximately %.3f after %i iterations",
  eigenvalue_a1, iterations_a1
)

ncaam_a1_eigenvalues |> 
  plot_lambdas() + 
  geom_hline(yintercept = eigenvalue_a1, linetype = "dashed") +
  labs(caption = plot_caption)
```

We use the approximated eigenvalue to compute the approximate eigenvector. We can use this eigenvector to compute rankings for NCAA men's basketball teams following the 2023-24 season. The rankings are shown below for the AP top 25 teams, showing that the win-loss method is an ineffective ranking scheme for NCAA men's basketball.

```{r ranking-comparison}
ncaam_a1_ranks <- 
  ncaam_a1_eigenvalues |> 
  rankings_from_eigenvalues()

ncaam_a1_ap_comparison <- 
  ncaam_a1_ranks |> 
  inner_join(ap, by = "team") |> 
  left_join(game_data_summary(ncaam), by = "team")

ncaam_a1_ap_comparison |> 
  plot_rank_comparison() +
  labs(
    title = "Performance of ranking approximation", 
    caption = "The win-loss ranking method is an ineffective ranking method.")
```

<br>

### Additional Ranking Methods

Additional variations of $a_{ij}$ did not produce better results. We used proportion of points, scored, various polynomial functions, distance between points scored, etc as values for $a_{ij}$.

To compare impact of values of $a_{ij}$ on the resulting eigenvalues, we calculated the sum of squared difference between the eigenvector and the win-ratio. We denote this sum of squared difference for a matrix $A_{i}$ $\vec e_{i}$ where $i$ denotes the ranking function used to create the matrix $A_{i}$. Let $\vec r_{i}$ denote the ranking vector for $A_{i}$ and $\vec q_{i}$ denote the win-ratio's for the teams in matrix $A_{i}$. That is,

$$
\vec q_{i}=\frac {\vec w_{i}}{\vec w_{i} + \vec l_{i}}
$$

where $\vec w_{i}$ represents the number of team $i$'s wins in a given season and $\vec l_{i}$ represents the number of team $i$'s losses. That leads us to the following definition of $\vec e_{i}$:

$$
\vec e_{i}=(\vec r_{i}-\vec q_{i})^2
$$

The best performing matrix is the $A_{i}$ that minimizes $\vec e_{i}$. We denote this matrix $A^*$, with entries $a^*_{ij}$.

The table below shows a summary of each $A_{i}$ with its corresponding $e_{i}$.

```{r}
eigenvalue_pipeline <- function(ranking_table_func, data) {
  data |> 
    ranking_table_func() |> 
    to_matrix() |> 
    eigenvalues_power_method() |> 
    rankings_from_eigenvalues() |> 
    dplyr::left_join(game_data_summary(data), by = "team")
}

ranking_functions <- list(
  direct_win_loss = ranking_table_prep_direct_win_loss,
  points_abs_distance = ranking_table_prep_points_abs_distance,
  points_difference_cond = ranking_table_prep_points_difference_cond,
  points_inverse = ranking_table_prep_points_inverse,
  points_inverse2 = ranking_table_prep_points_inverse2,
  points_inverse3 = ranking_table_prep_points_inverse3,
  points_polynomial1 = ranking_table_prep_points_polynomial1,
  points_polynomial2 = ranking_table_prep_points_polynomial2,
  points_polynomial3 = ranking_table_prep_points_polynomial3,
  points_polynomial4 = ranking_table_prep_points_polynomial4,
  points_polynomial5 = ranking_table_prep_points_polynomial5,
  points_proportion = ranking_table_prep_points_proportion,
  points_scored_mean = ranking_table_prep_points_scored_mean,
  points_sqrt_points = ranking_table_prep_points_sqrt_points,
  points_squared_distance = ranking_table_prep_points_squared_distance,
  points_run_up = ranking_table_prep_point_run_up
)

all_results <- function(data) {
  eigenvalue_pipeline_func <- function(func) eigenvalue_pipeline(func, data)
  purrr::map(ranking_functions, eigenvalue_pipeline_func)
}

ncaam_results <- all_results(ncaam)

ncaam_results_error <- 
  ncaam_results |> 
  map(mutate, e = (eigenvector - wr)^2) |> 
  map_dbl(~sum(.$e)) |> 
  sort() |> 
  enframe("ranking_table_name", "e")

top_ncaam_result <- ncaam_results[[ncaam_results_error$ranking_table_name[1]]]

ncaam_results_error |> 
  head(5) |> 
  gt() |> 
  fmt_number(columns = c("e"), decimals = 3) |> 
  tab_caption("Table showing the top five ranking matrices with corresponding error metrics")
```

<br>

The best performing table is the table with entries $a_{ij}$ constructed with the proportion of points scored in each game. That is,

$$
a^*_{ij}=\frac{s_{ij}}{s_{ij}+s_{ji}}
$$

The figure below shows the eigenvalues plotted against the win-ratio's for all 362 teams in the data using $a^*_{ij}$ as the entries for $A^*$. We also included plotted the linear regression line between the two points, for reference. We can see that for the full league, the eigenvalues bear little relationship to the win-ratios, suggesting that none of the tested ranking methods are effective at ranking the entire NCAA.

```{r}
ncaam_results[[ncaam_results_error$ranking_table_name[1]]] |> 
  ggplot() +
  aes(eigenvector, wr) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Win rate vs approximated strength",
    caption = "The top performing ranking scheme, plotted here against the win-ratios for the 362 teams in the dataset, is ineffective at ranking the entire NCAA")
```

<br>

### Sparsity

One issue effecting results in the sparsity of the ranking matrices we are using. When analyzing the matrix comprised of 362 teams x 362 teams, most of whom do not face each other in the regular season, the matrix is going to be mostly sparse.

To explore the role of sparsity, we look at a second, filtered dataset, comprising of in-conference games between PAC-12 teams. That is, we only look at games in which two PAC-12 teams played each other. The figure below shows the same 5 ranking schemes are the most effective ranking schemes.

```{r}
pac12_results <- all_results(pac12)

pac12_results_error <- 
  pac12_results |> 
  map(mutate, e = (eigenvector - wr)^2) |> 
  map_dbl(~sum(.$e)) |> 
  sort() |> 
  enframe("ranking_table_name", "e")

pac12_top_result <- pac12_results[[pac12_results_error$ranking_table_name[1]]]

pac12_results_error |> 
  head(5) |> 
  gt() |> 
  fmt_number(columns = c("e"), decimals = 3) |> 
  tab_caption("Table showing the top five ranking matrices with corresponding error metrics")
```

<br>

Looking at the relationship between the eigenvector and the win-ratio, we see a much stronger relationship, suggesting sparsity limits the effectiveness of theme ranking schemes.

```{r}
pac12_top_result |> 
  ggplot() +
  aes(eigenvector, wr) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Win rate vs approximated strength",
    caption = "When limited to conference play, the ranking method via proportion is an effective ranking method."
  )
```

The table below shows the ranking for PAC-12 using the proportion ranking matrix.

```{r}
pac12_top_result |> 
  select(team, eigenvector, rank, w, l, wr) |> 
  gt() |> 
  fmt_number(columns = c("eigenvector", "wr"), decimals = 3) |> 
  tab_caption("Rankings for in-conference PAC-12 play for the NCAA men's 2023-24 basketball season as obtained via the proportion ranking matrix")
```
